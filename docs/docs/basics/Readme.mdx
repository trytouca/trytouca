import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import ToucaImage from "@site/src/components/ToucaImage";

# Quick Start

Welcome! If you are new to Touca, this is the right place to be! Our main
objective here is to introduce Touca without taking too much of your time.

## Revisiting Unit Testing

Let's assume that we want to test a software that checks whether a given number
is prime.

<Tabs
  groupId="sdks"
  defaultValue="python"
  values={[
    { label: "Python", value: "python" },
    { label: "C++", value: "cpp" },
    { label: "TypeScript", value: "js" },
    { label: "Java", value: "java" }
  ]}
>
  <TabItem value="python">

```python title="01_python_minimal/is_prime.py"
def is_prime(number: int):
    for i in range(2, number):
        if number % i == 0:
            return False
    return 1 < number
```

  </TabItem>
  <TabItem value="cpp">

```cpp title="01_cpp_minimal/is_prime.hpp"
#include <cmath>

bool is_prime(const unsigned long number) {
  for (auto i = 2u; i < number; i++) {
    if (number % i == 0) {
      return false;
    }
  }
  return 1 < number;
}
```

  </TabItem>
  <TabItem value="js">

```typescript title="01_node_minimal/is_prime.ts"
export function is_prime(input: number): boolean {
  for (let i = 2; i < input; i++) {
    if (input % i === 0) {
      return false;
    }
  }
  return 1 < input;
}
```

  </TabItem>
  <TabItem value="java">

```java title="01_java_minimal/Prime.java"
public final class Prime {
  public static boolean isPrime(final int number) {
    for (int i = 2; i < number; i++) {
      if (number % i == 0) {
        return false;
      }
    }
    return 1 < number;
  }
}
```

  </TabItem>
</Tabs>

We can use unit testing in which we hard-code a set of input numbers and list
our expected return value for each input.

<Tabs
  groupId="sdks"
  defaultValue="python"
  values={[
    { label: "Python", value: "python" },
    { label: "C++", value: "cpp" },
    { label: "TypeScript", value: "js" },
    { label: "Java", value: "java" }
  ]}
>
  <TabItem value="python">

```python
from code_under_test import is_prime

def test_is_prime():
    assert is_prime(-1) == False
    assert is_prime(1)  == False
    assert is_prime(2)  == True
    assert is_prime(13) == True
```

  </TabItem>
  <TabItem value="cpp">

```cpp
#include "catch2/catch.hpp"
#include "code_under_test.hpp"

TEST_CASE("is_prime") {
  CHECK(is_prime(-1) == false);
  CHECK(is_prime(1) == false);
  CHECK(is_prime(2) == true);
  CHECK(is_prime(13) == true);
}
```

  </TabItem>
  <TabItem value="js">

```typescript
import { is_prime } from "code_under_test";

test("test is_prime", () => {
  expect(is_prime(-1)).toEqual(false);
  expect(is_prime(1)).toEqual(false);
  expect(is_prime(2)).toEqual(true);
  expect(is_prime(13)).toEqual(true);
});
```

  </TabItem>
  <TabItem value="java">

```java
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.assertFalse;
import static org.junit.jupiter.api.Assertions.assertTrue;

public final class PrimeTest {

  @Test
  public void isPrime() {
    assertFalse(Prime.isPrime(-1));
    assertFalse(Prime.isPrime(1));
    assertTrue(Prime.isPrime(2));
    assertTrue(Prime.isPrime(13));
  }
}
```

  </TabItem>
</Tabs>

With unit testing:

- For each input, we need to specify the corresponding expected output, as part
  of our test logic.
- As our software requirements evolve, we may need to go back and change our
  expected outputs.
- When we find other interesting inputs, we may need to go back and include them
  in our set of inputs.

In our example, the input and output of our code under test are a number and a
boolean. If we were testing a video compression algorithm, they may have been
video files. In that case:

- Describing the expected output for a given video file would be difficult.
- When we make changes to our compression algorithm, accurately reflecting those
  changes in our expected values would be time-consuming.
- We would need a large number of input video files to gain confidence that our
  algorithm works correctly.

## Introducing Touca

Touca makes it easier to continuously test workflows of any complexity and with
any number of test cases.

<Tabs
  groupId="sdks"
  defaultValue="python"
  values={[
    { label: "Python", value: "python" },
    { label: "C++", value: "cpp" },
    { label: "TypeScript", value: "js" },
    { label: "Java", value: "java" }
  ]}
>
  <TabItem value="python">

```python title="01_python_minimal/is_prime_test.py"
import touca
from is_prime import is_prime

@touca.Workflow
def is_prime_test(testcase: str):
    touca.check("output", is_prime(int(testcase)))
```

  </TabItem>
  <TabItem value="cpp">

```cpp
#include "is_prime.hpp"
#include "touca/touca.hpp"

int main(int argc, char* argv[]) {
  touca::workflow("is_prime_test", [](const std::string& testcase) {
    const auto number = std::stoul(testcase);
    touca::check("output", is_prime(number));
  });
  return touca::run(argc, argv);
}
```

  </TabItem>
  <TabItem value="js">

```typescript title="01_node_minimal/is_prime_test.ts"
import { touca } from "@touca/node";
import { is_prime } from "./is_prime";

touca.workflow("is_prime_test", (testcase: string) => {
  const number = Number.parseInt(testcase);
  touca.check("output", is_prime(number));
});

touca.run();
```

  </TabItem>
  <TabItem value="java">

```java
import io.touca.Touca;

public final class PrimeTest {

  @Touca.Workflow
  public void isPrime(final String testcase) {
    final int number = Integer.parseInt(testcase);
    Touca.check("output", Prime.isPrime(number));
  }

  public static void main(String[] args) {
    Touca.run(PrimeTest.class, args);
  }
}
```

  </TabItem>
</Tabs>

This is slightly different from a typical unit test:

- Touca tests do not use expected values.
- Touca tests do not hard-code input values.

With Touca, we can define how to run our code under test for any given test
case. We can capture values of interesting variables and runtime of important
functions to describe the behavior and performance of our workflow for that test
case. Touca SDKs submit this description to a remote Touca server which compares
it against the description for a trusted version of our code. The server
visualizes any differences and reports them in near real-time.

We can run Touca tests with any number of inputs from the command line:

<Tabs
  groupId="sdks"
  defaultValue="python"
  values={[
    { label: "Python", value: "python" },
    { label: "C++", value: "cpp" },
    { label: "TypeScript", value: "js" },
    { label: "Java", value: "java" }
  ]}
>
  <TabItem value="python">

```bash
git clone git@github.com:trytouca/trytouca.git
cd trytouca/examples/python
python -m venv .env
source .env/bin/activate
pip install touca
cd 01_python_minimal
```

```bash
touca config set api-key=<TOUCA_API_KEY>
touca config set api-url=<TOUCA_API_URL>
touca test --revision v1.0 --testcase 13 17 51
```

  </TabItem>
  <TabItem value="cpp">

```bash
git clone git@github.com:trytouca/trytouca.git
cd trytouca/examples/cpp
./build.sh
```

```bash
export TOUCA_API_KEY=<TOUCA_API_KEY>
export TOUCA_API_URL=<TOUCA_API_URL>
./local/dist/bin/example_cpp_minimal --revision v1.0 --testcase 13,17,51
```

  </TabItem>
  <TabItem value="js">

```bash
git clone git@github.com:trytouca/trytouca.git
cd trytouca/examples/js
npm install
npm run build
```

```bash
export TOUCA_API_KEY=<TOUCA_API_KEY>
export TOUCA_API_URL=<TOUCA_API_URL>
node 01_node_minimal/dist/is_prime_test.js --revision v1.0 --testcase 13 17 51
```

  </TabItem>
  <TabItem value="java">

```bash
git clone git@github.com:trytouca/trytouca.git
cd trytouca/examples/java
./gradlew build
```

```bash
export TOUCA_API_KEY=<TOUCA_API_KEY>
export TOUCA_API_URL=<TOUCA_API_URL>
gradle runExampleMinimal --args='--revision v1.0 --testcase 13 17 51'
```

  </TabItem>
</Tabs>

Where API Key and URL can be obtained from the Touca server at
[app.touca.io](https://app.touca.io) or your own self-hosted instance.

This command produces the following output:

```text

Touca Test Framework
Suite: is_prime_test/v1.0

 1.  PASS   13    (127 ms)
 2.  PASS   17    (123 ms)
 3.  PASS   51    (159 ms)

Tests:      3 passed, 3 total
Time:       0.57 s

✨   Ran all test suites.

```

<ToucaImage
  src="touca-sdk-quickstart-1.png"
  dark="touca-sdk-quickstart-1-dark.png"
  alt="Touca server after submitting results for v1.0"
/>

Now if we make changes to our workflow under test, we can rerun this test and
rely on Touca to check if our changes affected the behavior or performance of
our software.

<Tabs
  groupId="sdks"
  defaultValue="python"
  values={[
    { label: "Python", value: "python" },
    { label: "C++", value: "cpp" },
    { label: "TypeScript", value: "js" },
    { label: "Java", value: "java" }
  ]}
>
  <TabItem value="python">

```bash
touca test
```

  </TabItem>
  <TabItem value="cpp">

```bash
./local/dist/bin/example_cpp_minimal --revision v1.1
```

  </TabItem>
  <TabItem value="js">

```bash
node 01_node_minimal/dist/is_prime_test.js --revision v1.1
```

  </TabItem>
  <TabItem value="java">

```bash
gradle runExampleMinimal --args='--revision v1.1'
```

  </TabItem>
</Tabs>

```text

Touca Test Framework
Suite: is_prime_test/v1.1

 1.  SENT   13    (109 ms)
 2.  SENT   17    (152 ms)
 3.  SENT   51    (127 ms)

Tests:      3 passed, 3 total
Time:       0.55 s

✨   Ran all test suites.

```

<ToucaImage
  src="touca-sdk-quickstart-2.png"
  dark="touca-sdk-quickstart-2-dark.png"
  alt="Touca server after submitting results for v1.1"
/>

Unlike integration tests, we are not bound to the output of our workflow. We can
capture any number of data points and from anywhere within our code. This is
specially useful if our workflow has multiple stages. We can capture the output
of each stage without publicly exposing its API. When any stage changes behavior
in a future version of our software, our captured data points will help find the
root cause more easily.

## Summary

Touca is very effective in addressing common problems in the following
situations:

- When we need to test our workflow with a large number of inputs.
- When the output of our workflow is too complex, or too difficult to describe
  in our unit tests.
- When interesting information to check for regression is not exposed through
  the interface of our workflow.

The highlighted design features of Touca can help us test these workflows at any
scale.

- Decoupling our test input from our test logic, can help us manage our long
  list of inputs without modifying the test logic. Managing that list on a
  remote server accessible to all members of our team, can help us add notes to
  each test case, explain why they are needed and track how their performance
  changes over time.
- Submitting our test results to a remote server, instead of storing them in
  files, can help us avoid the mundane tasks of managing and processing of those
  results. The Touca server retains test results and makes them accessible to
  all members of the team. It compares test results using their original data
  types and reports discovered differences in real-time to all interested
  members of our team. It allows us to audit how our software evolves over time
  and provides high-level information about our tests.

<ToucaImage src="touca-suite-page.png" dark="touca-suite-page-dark.png" />
